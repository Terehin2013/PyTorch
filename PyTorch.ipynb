{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJ6u4wY8oXQAfGG1mar9Jw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5yzaTFzZB9Oz","executionInfo":{"status":"ok","timestamp":1741297564600,"user_tz":-180,"elapsed":7580,"user":{"displayName":"Андрей Нефедов","userId":"15888708031201590428"}},"outputId":"0a265816-f7db-41f1-982e-ac492cfc130f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.21)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Папка /content/drive/MyDrive/color_dataset найдена. Доступ к данным разрешен.\n","Found 1803 images belonging to 12 classes.\n","Found 447 images belonging to 12 classes.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n","Основной цвет изображения: Red\n"]}],"source":["# Устанавливаем необходимые библиотеки\n","!pip install tensorflow opencv-python\n","\n","# Монтируем Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import numpy as np\n","import cv2\n","import os\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from PIL import Image\n","import numpy as np\n","\n","# Указываем путь к директории с данными на Google Drive\n","data_dir = '/content/drive/MyDrive/color_dataset'  # Заменить на свой путь к папке с изображениями\n","\n","# Проверка, существует ли папка с данными\n","if not os.path.exists(data_dir):\n","    print(f\"Папка {data_dir} не найдена. Проверьте путь к папке.\")\n","else:\n","    print(f\"Папка {data_dir} найдена. Доступ к данным разрешен.\")\n","\n","    # Используем ImageDataGenerator для загрузки и аугментации данных\n","    train_datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n","\n","    # Загрузка тренировочных данных\n","    train_generator = train_datagen.flow_from_directory(\n","        data_dir,\n","        target_size=(128, 128),\n","        batch_size=32,\n","        class_mode='sparse',  # Для многоклассовой классификации\n","        subset='training'\n","    )\n","\n","    # Загрузка данных для валидации\n","    validation_generator = train_datagen.flow_from_directory(\n","        data_dir,\n","        target_size=(128, 128),\n","        batch_size=32,\n","        class_mode='sparse',  # Для многоклассовой классификации\n","        subset='validation'\n","    )\n","\n","    # Создание модели нейронной сети\n","    def create_model():\n","        model = models.Sequential([\n","            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n","            layers.MaxPooling2D((2, 2)),\n","            layers.Conv2D(64, (3, 3), activation='relu'),\n","            layers.MaxPooling2D((2, 2)),\n","            layers.Conv2D(128, (3, 3), activation='relu'),\n","            layers.MaxPooling2D((2, 2)),\n","            layers.Flatten(),\n","            layers.Dense(128, activation='relu'),\n","            layers.Dense(train_generator.num_classes, activation='softmax')  # Классы равны количеству цветов\n","        ])\n","        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        return model\n","\n","    # Создаем модель\n","    model = create_model()\n","\n","\n","    # Сохраняем модель\n","    model.save('/content/drive/MyDrive/color_classifier.h5')\n","\n","    # Функция для предсказания цвета изображения\n","    def predict_color(model, image_path):\n","    # Загружаем и подготавливаем изображение с использованием PIL\n","      img = Image.open(image_path)\n","\n","    # Преобразуем изображение в формат RGB, если оно в другом формате (например, RGBA)\n","      img = img.convert('RGB')\n","\n","      img = img.resize((128, 128))  # Изменяем размер изображения\n","      img = np.array(img) / 255.0  # Нормализуем изображение\n","\n","    # Добавляем размерность для пакета (batch)\n","      img = np.expand_dims(img, axis=0)\n","\n","    # Прогнозируем\n","      prediction = model.predict(img)\n","      class_idx = np.argmax(prediction)  # Индекс с наибольшей вероятностью\n","\n","    # Получаем метки классов (цвета)\n","      class_labels = list(train_generator.class_indices.keys())  # Метки классов\n","      return class_labels[class_idx]\n","\n","    # Прогнозирование для изображения (замени путь на нужное изображение)\n","    image_path = '/content/drive/MyDrive/4.jpeg'  # Заменить на путь к изображению\n","    predicted_color = predict_color(model, image_path)\n","    print(f'Основной цвет изображения: {predicted_color}')\n"]},{"cell_type":"code","source":[" # Обучение модели\n","model.fit(train_generator, epochs=10, validation_data=validation_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2417jFgnRRyn","executionInfo":{"status":"ok","timestamp":1741297440979,"user_tz":-180,"elapsed":713695,"user":{"displayName":"Андрей Нефедов","userId":"15888708031201590428"}},"outputId":"31efd6f6-abb9-48e9-be88-27b3c708146d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.3992 - loss: 1.6579 - val_accuracy: 0.6331 - val_loss: 0.9838\n","Epoch 2/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.6716 - loss: 0.8532 - val_accuracy: 0.6667 - val_loss: 0.8442\n","Epoch 3/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7322 - loss: 0.6837 - val_accuracy: 0.7136 - val_loss: 0.7937\n","Epoch 4/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7766 - loss: 0.6180 - val_accuracy: 0.6600 - val_loss: 0.8847\n","Epoch 5/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7588 - loss: 0.5980 - val_accuracy: 0.7494 - val_loss: 0.7076\n","Epoch 6/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.7932 - loss: 0.4979 - val_accuracy: 0.7651 - val_loss: 0.6939\n","Epoch 7/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - accuracy: 0.7897 - loss: 0.5585 - val_accuracy: 0.7114 - val_loss: 0.7340\n","Epoch 8/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.7981 - loss: 0.4846 - val_accuracy: 0.8009 - val_loss: 0.6201\n","Epoch 9/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.8635 - loss: 0.3519 - val_accuracy: 0.7606 - val_loss: 0.5981\n","Epoch 10/10\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.8673 - loss: 0.3449 - val_accuracy: 0.7942 - val_loss: 0.5722\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x781f04eed390>"]},"metadata":{},"execution_count":23}]}]}